# streamlit_app.py
# K-pop æ²‰æµ¸å¼éŸ©è¯­å­¦ä¹ åŠ©æ‰‹ â€” MVP æ¼”ç¤ºåŸå‹
# åŠŸèƒ½ï¼š
# 1) å¤šè¯­è¨€ UIï¼ˆä¸­/éŸ©/è‹±ï¼‰
# 2) Weverse ç›´æ’­è§£ææ¨¡æ‹Ÿï¼šè¾“å…¥ URL -> åŠ è½½æ¨¡æ‹Ÿè§†é¢‘ + åŒè¯­å­—å¹•æµ
# 3) äº¤äº’å¼å­¦ä¹ ä¸ç”Ÿè¯æœ¬ï¼ˆç‚¹å‡»è¯æŸ¥çœ‹è¯¦æƒ…å¹¶åŠ å…¥ç”Ÿè¯æœ¬ï¼‰
# 4) TOPIK æ°´å¹³è‡ªæµ‹ï¼ˆ5-8 é¢˜ï¼Œè‡ªåŠ¨è¯„åˆ†ä¸ç­‰çº§ä¼°è®¡ï¼‰
# 5) çˆ±è±†è¯­è¨€ç”»åƒï¼ˆç¤ºä¾‹æ•°æ®ï¼šä»¥ BTS æˆå‘˜ä¸ºä¾‹ï¼Œå±•ç¤ºé«˜é¢‘è¯/å‰¯è¯ç»Ÿè®¡/è¯­æ€åˆ†æï¼‰
#
# æ³¨æ„ï¼šæœ¬æ¼”ç¤ºä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼Œæ— éœ€ä»»ä½•å¤–éƒ¨ APIï¼Œç›´æ¥è¿è¡Œå³å¯ã€‚
# å¦å¤–ï¼šæ ¹æ®å¼€å‘è€…æŒ‡ç¤ºï¼Œè¿™é‡Œå°†ç¤ºä¾‹â€œä¸Šä¼ æ–‡ä»¶â€è·¯å¾„ä»¥æœ¬åœ°è·¯å¾„æ–¹å¼ä½¿ç”¨ï¼ˆç”¨äºæ¼”ç¤ºå ä½å›¾/è§†é¢‘ï¼‰ã€‚
# ä½¿ç”¨åˆ°çš„æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼ˆæ¥è‡ªä½ ä¸Šä¼ çš„æ–‡ä»¶å†å²ï¼‰ï¼š
#   /mnt/data/1999D0C2-880F-462A-854D-9D6B870CC9E2.jpeg
#   /mnt/data/B52A860B-7AEF-4BF7-8D58-7095346AA56B.jpeg

import streamlit as st
import pandas as pd
import numpy as np
import time
import json
from datetime import timedelta
import matplotlib.pyplot as plt
from io import BytesIO

st.set_page_config(page_title="K-pop éŸ©è¯­å­¦ä¹ åŠ©æ‰‹ â€” ianå­—å¹• MVP", layout="wide")

# -------------------------
# 1. MULTI-LANGUAGE DICTIONARY
# -------------------------
LANG = {
    "zh": {
        "title": "K-pop æ²‰æµ¸å¼éŸ©è¯­å­¦ä¹ åŠ©æ‰‹",
        "weverse_input": "ç²˜è´´ Weverse ç›´æ’­é“¾æ¥ï¼ˆç¤ºä¾‹æ¨¡å¼ï¼‰",
        "load_demo": "åŠ è½½ç¤ºä¾‹ç›´æ’­",
        "start_sim": "å¼€å§‹æ¨¡æ‹Ÿæ’­æ”¾",
        "stop_sim": "åœæ­¢",
        "vocab_book": "æˆ‘çš„ç”Ÿè¯æœ¬",
        "add_vocab": "æ·»åŠ åˆ°ç”Ÿè¯æœ¬",
        "test": "èƒ½åŠ›æµ‹è¯•",
        "insight": "çˆ±è±†è¯­è¨€ç”»åƒ (Idol Insight)",
        "export_subs": "å¯¼å‡ºå­—å¹• (SRT / TXT)",
        "select_lang": "ç•Œé¢è¯­è¨€ / Interface Language",
        "subtitle_area": "å­—å¹•åŒºï¼ˆç‚¹å‡»é«˜äº®è¯æŸ¥çœ‹è¯¦æƒ…ï¼‰",
        "explain": "è¯è¯­è§£é‡Š",
        "orig": "åŸæ–‡",
        "trans": "è¯‘æ–‡",
        "difficulty": "TOPIK ç­‰çº§ä¼°è®¡",
        "score": "å¾—åˆ†",
        "level": "é¢„è®¡ TOPIK ç­‰çº§",
        "no_vocab": "ä½ è¿˜æ²¡æœ‰æ”¶è—å•è¯ã€‚",
        "remove": "ä»ç”Ÿè¯æœ¬ç§»é™¤",
    },
    "ko": {
        "title": "K-pop ëª°ì…í˜• í•œêµ­ì–´ í•™ìŠµ ë„ìš°ë¯¸",
        "weverse_input": "Weverse ë¼ì´ë¸Œ ë§í¬ ë¶™ì—¬ë„£ê¸° (ë°ëª¨ ëª¨ë“œ)",
        "load_demo": "ë°ëª¨ ë¼ì´ë¸Œ ë¶ˆëŸ¬ì˜¤ê¸°",
        "start_sim": "ì‹œë®¬ë ˆì´ì…˜ ì¬ìƒ",
        "stop_sim": "ì¤‘ì§€",
        "vocab_book": "ë‚´ ë‹¨ì–´ì¥",
        "add_vocab": "ë‹¨ì–´ì¥ì— ì¶”ê°€",
        "test": "ì‹¤ë ¥ í…ŒìŠ¤íŠ¸",
        "insight": "ì•„ì´ëŒ ì–¸ì–´ ì¸ì‚¬ì´íŠ¸",
        "export_subs": "ìë§‰ ë‚´ë³´ë‚´ê¸° (SRT / TXT)",
        "select_lang": "ì¸í„°í˜ì´ìŠ¤ ì–¸ì–´ / Interface Language",
        "subtitle_area": "ìë§‰ ì˜ì—­ (í•˜ì´ë¼ì´íŠ¸ ë‹¨ì–´ í´ë¦­)",
        "explain": "ë‹¨ì–´ ì„¤ëª…",
        "orig": "ì›ë¬¸",
        "trans": "ë²ˆì—­",
        "difficulty": "TOPIK ë ˆë²¨ ì¶”ì •",
        "score": "ì ìˆ˜",
        "level": "ì˜ˆìƒ TOPIK ë ˆë²¨",
        "no_vocab": "ì•„ì§ ì €ì¥ëœ ë‹¨ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.",
        "remove": "ë‹¨ì–´ì¥ ì‚­ì œ",
    },
    "en": {
        "title": "K-pop Immersive Korean Study Assistant",
        "weverse_input": "Paste Weverse live URL (demo mode)",
        "load_demo": "Load demo live",
        "start_sim": "Start simulation",
        "stop_sim": "Stop",
        "vocab_book": "My Vocab Book",
        "add_vocab": "Add to Vocab",
        "test": "Proficiency Test",
        "insight": "Idol Language Insight",
        "export_subs": "Export subtitles (SRT / TXT)",
        "select_lang": "Interface Language / ç•Œé¢è¯­è¨€",
        "subtitle_area": "Subtitles area (click highlighted words)",
        "explain": "Word Explanation",
        "orig": "Original",
        "trans": "Translation",
        "difficulty": "TOPIK level estimate",
        "score": "Score",
        "level": "Estimated TOPIK level",
        "no_vocab": "You have no saved vocab yet.",
        "remove": "Remove from vocab",
    }
}

# -------------------------
# Helpers & Session State
# -------------------------
if "lang" not in st.session_state:
    st.session_state.lang = "zh"
if "vocab" not in st.session_state:
    st.session_state.vocab = {}  # word -> {info...}
if "subs_buffer" not in st.session_state:
    st.session_state.subs_buffer = []  # subtitle list
if "sim_playing" not in st.session_state:
    st.session_state.sim_playing = False
if "current_time" not in st.session_state:
    st.session_state.current_time = 0  # milliseconds relative to start
if "weverse_demo_loaded" not in st.session_state:
    st.session_state.weverse_demo_loaded = False
if "test_results" not in st.session_state:
    st.session_state.test_results = None

# translation for UI text
def T(key):
    return LANG[st.session_state.lang].get(key, key)

# -------------------------
# Sidebar: language & navigation
# -------------------------
with st.sidebar:
    st.selectbox(
        T("select_lang"),
        options=[("ä¸­æ–‡", "zh"), ("í•œêµ­ì–´", "ko"), ("English", "en")],
        index=["zh", "ko", "en"].index(st.session_state.lang),
        format_func=lambda x: x[0],
        key="ui_lang_select",
        on_change=lambda: st.session_state.update({"lang": st.session_state.ui_lang_select})
    )
    st.title(T("title"))
    page = st.radio("", ["Live Study", T("test"), T("insight"), T("vocab_book")], index=0)
    st.markdown("---")
    st.markdown("**Quick actions**")
    if st.button(T("load_demo")):
        st.session_state.weverse_demo_loaded = False  # reset to force reload

# -------------------------
# Simulated Data: video + subtitles + TOPIK vocab tags
# -------------------------
# Developer-provided local file path used as placeholder "media" (per instructions)
LOCAL_MEDIA_PLACEHOLDER = "/mnt/data/1999D0C2-880F-462A-854D-9D6B870CC9E2.jpeg"
ALT_MEDIA_PLACEHOLDER = "/mnt/data/B52A860B-7AEF-4BF7-8D58-7095346AA56B.jpeg"

# Example subtitle stream (timestamps in ms relative to start)
SIM_SUBS = [
    {"start": 0, "end": 3500, "orig": "ì•ˆë…•í•˜ì„¸ìš” ì—¬ëŸ¬ë¶„, ì˜¤ëŠ˜ì€ ì‹ ê³¡ ë¦¬í—ˆì„¤ì´ ìˆì–´ìš”.", "trans": "å¤§å®¶å¥½ï¼Œä»Šå¤©æœ‰æ–°æ­Œæ’ç»ƒã€‚"},
    {"start": 4000, "end": 7500, "orig": "ì´ ë…¸ë˜ëŠ” ê°€ì‚¬ì— ì–´ë ¤ìš´ í‘œí˜„ì´ ë§ì•„ìš”.", "trans": "è¿™é¦–æ­Œçš„æ­Œè¯æœ‰å¾ˆå¤šéš¾æ‡‚çš„è¡¨è¾¾ã€‚"},
    {"start": 8000, "end": 11500, "orig": "í•˜ì§€ë§Œ ì—°ìŠµí•˜ë©´ ê¸ˆë°© ìµí ìˆ˜ ìˆìŠµë‹ˆë‹¤.", "trans": "ä½†æ˜¯ç»ƒä¹ çš„è¯å¾ˆå¿«å°±èƒ½æŒæ¡ã€‚"},
    {"start": 12000, "end": 15500, "orig": "ë°œìŒì— ì‹ ê²½ ì¨ì£¼ì„¸ìš” â€” íŠ¹íˆ ë°›ì¹¨ ë°œìŒ.", "trans": "è¯·æ³¨æ„å‘éŸ³ï¼Œå°¤å…¶æ˜¯å°¾éŸ³ã€‚"},
    {"start": 16000, "end": 19500, "orig": "ì, ìš°ë¦¬ ë‹¤ì‹œ í•œ ë²ˆ í•´ë³¼ê¹Œìš”?", "trans": "æ¥ï¼Œæˆ‘ä»¬å†è¯•ä¸€æ¬¡å§ï¼Ÿ"},
]

# TOPIK-related words in the subtitles with simulated metadata
TOPIK_WORDS = {
    "ì•ˆë…•í•˜ì„¸ìš”": {"level": 1, "lemma": "ì•ˆë…•í•˜ë‹¤", "notes": "å¸¸ç”¨é—®å€™è¯­ã€‚"},
    "ì‹ ê³¡": {"level": 3, "lemma": "ì‹ ê³¡", "notes": "æ–°å‘å¸ƒçš„æ­Œæ›²ã€‚"},
    "ë¦¬í—ˆì„¤": {"level": 4, "lemma": "ë¦¬í—ˆì„¤(ì—°ìŠµ)", "notes": "æ’ç»ƒï¼Œå½©æ’ã€‚"},
    "ê°€ì‚¬": {"level": 3, "lemma": "ê°€ì‚¬", "notes": "æ­Œè¯ã€‚"},
    "ë°œìŒ": {"level": 2, "lemma": "ë°œìŒ", "notes": "å‘éŸ³ã€‚"},
    "ë°›ì¹¨": {"level": 5, "lemma": "ë°›ì¹¨", "notes": "éŸ©è¯­éŸ³èŠ‚æœ«çš„æ”¶å°¾è¾…éŸ³ã€‚"},
    "ì—°ìŠµ": {"level": 2, "lemma": "ì—°ìŠµí•˜ë‹¤", "notes": "ç»ƒä¹ ã€‚"},
}

# Utility: simple "AI explanation" generator (simulated)
def explain_word(word):
    meta = TOPIK_WORDS.get(word, None)
    if meta:
        return {
            "word": word,
            "lemma": meta["lemma"],
            "level": meta["level"],
            "explain_cn": f"ï¼ˆæ¨¡æ‹Ÿï¼‰{word} çš„ä¸­æ–‡è§£é‡Šï¼š{meta['notes']}",
            "explain_kr": f"(ì‹œë®¬ë ˆì´ì…˜) {word}ì˜ ì„¤ëª…: {meta['notes']}",
            "grammar": f"ç¤ºä¾‹ï¼š{meta['lemma']} + (ìœ¼)ë©´ ...",
        }
    else:
        # fallback simulated explanation
        return {
            "word": word,
            "lemma": word,
            "level": "unknown",
            "explain_cn": f"ï¼ˆæ¨¡æ‹Ÿï¼‰{word}ï¼šæš‚æ— è¯¦ç»†ä¿¡æ¯ï¼Œå»ºè®®æ ‡æ³¨ä¸ºå¤ä¹ å•è¯ã€‚",
            "explain_kr": f"(ì‹œë®¬ë ˆì´ì…˜) {word}: ì •ë³´ ì—†ìŒ.",
            "grammar": "æš‚æ— "
        }

# -------------------------
# Page: Live Study (main)
# -------------------------
def page_live_study():
    st.header(T("title"))
    col1, col2 = st.columns([2, 1])
    with col1:
        st.subheader(T("weverse_input"))
        url_input = st.text_input(T("weverse_input"), placeholder="https://weverse.example/live/...")
        if st.button(T("load_demo") + " (Demo)"):
            # load simulated data
            st.session_state.subs_buffer = SIM_SUBS.copy()
            st.session_state.weverse_demo_loaded = True
            st.success("å·²åŠ è½½ç¤ºä¾‹ç›´æ’­ä¸å­—å¹•ï¼ˆæ¼”ç¤ºæ¨¡å¼ï¼‰ã€‚")
        if st.session_state.weverse_demo_loaded:
            # show media placeholder (local file path used)
            try:
                # If it's an image, display; if a video file existed, st.video would work similarly.
                st.image(LOCAL_MEDIA_PLACEHOLDER, caption="ç¤ºä¾‹ç›´æ’­ç”»é¢ï¼ˆå ä½ï¼‰", use_column_width=True)
            except Exception:
                st.image(ALT_MEDIA_PLACEHOLDER, caption="ç¤ºä¾‹ç›´æ’­ç”»é¢ï¼ˆå ä½ï¼‰", use_column_width=True)

            # Playback controls: simulate time with a slider and play/stop buttons
            cols = st.columns([1,1,4])
            if cols[0].button(T("start_sim")):
                st.session_state.sim_playing = True
                st.session_state.current_time = 0
                st.experimental_rerun()
            if cols[1].button(T("stop_sim")):
                st.session_state.sim_playing = False

            # simulate playback loop (non-blocking)
            placeholder = st.empty()
            # format ms to mm:ss
            def fmt(ms):
                s = int(ms/1000)
                return f"{s//60:02d}:{s%60:02d}"
            # slider to inspect timeline
            max_t = st.session_state.subs_buffer[-1]["end"] if st.session_state.subs_buffer else 20000
            t_slider = cols[2].slider("æ—¶é—´è½´", 0, int(max_t), int(st.session_state.current_time), step=500, key="time_slider")
            st.session_state.current_time = t_slider

            if st.session_state.sim_playing:
                # increment time a little and rerun to simulate motion
                st.session_state.current_time = min(max_t, st.session_state.current_time + 1500)
                time.sleep(0.3)
                st.experimental_rerun()

            # show active subtitles based on current_time
            st.markdown("### " + T("subtitle_area"))
            active = [s for s in st.session_state.subs_buffer if (s["start"] <= st.session_state.current_time <= s["end"])]
            if not active:
                # show the next upcoming line
                upcoming = [s for s in st.session_state.subs_buffer if s["start"] > st.session_state.current_time]
                if upcoming:
                    line = upcoming[0]
                else:
                    line = None
                if line:
                    st.info(f"{T('orig')}: {line['orig']}\n\n{T('trans')}: {line['trans']}")
                else:
                    st.write("â€”")
            else:
                # display active lines with word-level highlighting for TOPIK_WORDS
                for idx, line in enumerate(active):
                    # split orig into words (naive split by spaces and punctuation for demonstration)
                    words = []
                    temp = ""
                    for ch in line["orig"]:
                        if ch.isalnum() or '\uac00' <= ch <= '\ud7a3':  # Korean syllable range heuristic
                            temp += ch
                        else:
                            if temp:
                                words.append(temp)
                                temp = ""
                            words.append(ch)
                    if temp:
                        words.append(temp)
                    # Render with buttons for TOPIK words
                    sub_cols = st.columns([4, 1])
                    with sub_cols[0]:
                        st.write("")
                        line_container = st.container()
                        # We'll construct a row of inline elements; Streamlit has limited inline control,
                        # so we render as markdown mixing **bold** for highlighted words and provide "æŸ¥çœ‹ / æ·»åŠ " buttons below.
                        display_tokens = []
                        token_buttons = []
                        for i, token in enumerate(words):
                            if token.strip() and token in TOPIK_WORDS:
                                display_tokens.append(f"**<span style='color:#d63384'>{token}</span>**")
                            else:
                                display_tokens.append(token.replace("\n", " "))
                        md = " ".join(display_tokens)
                        # Use unsafe_allow_html via st.markdown to display colored tokens
                        line_container.markdown(md, unsafe_allow_html=True)
                        line_container.markdown(f"*{T('trans')}:* {line['trans']}")
                        # Buttons for each TOPIK word in this line
                        for w in sorted(set([t for t in words if t in TOPIK_WORDS])):
                            bcol1, bcol2 = st.columns([1,4])
                            with bcol1:
                                if st.button(f"ğŸ” {w}", key=f"explain_{w}_{idx}"):
                                    st.session_state.last_explain = explain_word(w)
                            with bcol2:
                                if st.button(T("add_vocab"), key=f"add_{w}_{idx}"):
                                    info = explain_word(w)
                                    st.session_state.vocab[w] = info
                                    st.success(f"å·²åŠ å…¥ç”Ÿè¯æœ¬ï¼š{w}")
                    with sub_cols[1]:
                        # show timestamp
                        st.caption(f"{fmt(line['start'])} - {fmt(line['end'])}")

            # Export subtitles
            st.markdown("---")
            if st.button(T("export_subs")):
                # Default to SRT
                srt = subs_to_srt(st.session_state.subs_buffer)
                st.download_button("Download SRT", srt, file_name="ian_subtitles.srt", mime="text/plain")
    with col2:
        st.subheader(T("vocab_book"))
        # show user's vocab book
        if not st.session_state.vocab:
            st.info(T("no_vocab"))
        else:
            for w, info in st.session_state.vocab.items():
                with st.expander(f"{w}  â€”  TOPIK {info.get('level')}"):
                    st.write(T("explain"))
                    if st.session_state.lang == "ko":
                        st.write(info.get("explain_kr"))
                    else:
                        st.write(info.get("explain_cn"))
                    st.write("**Lemma:**", info.get("lemma"))
                    if st.button(T("remove"), key=f"remove_{w}"):
                        del st.session_state.vocab[w]
                        st.experimental_rerun()


# -------------------------
# Subtitle export helper
# -------------------------
def ms_to_srt_time(ms):
    s = int(ms / 1000)
    hh = s // 3600
    mm = (s % 3600) // 60
    ss = s % 60
    mmm = int(ms % 1000)
    return f"{hh:02d}:{mm:02d}:{ss:02d},{mmm:03d}"

def subs_to_srt(subs):
    out = ""
    for i, s in enumerate(subs, 1):
        out += f"{i}\n"
        out += f"{ms_to_srt_time(s['start'])} --> {ms_to_srt_time(s['end'])}\n"
        out += f"{s['orig']}\n{s['trans']}\n\n"
    return out

def subs_to_txt(subs):
    lines = []
    for s in subs:
        t = timedelta(milliseconds=s['start'])
        lines.append(f"[{str(t)}] {s['orig']} / {s['trans']}")
    return "\n".join(lines)

# -------------------------
# Page: Vocab Book (shortcut)
# -------------------------
def page_vocab():
    st.header(T("vocab_book"))
    if not st.session_state.vocab:
        st.info(T("no_vocab"))
    else:
        df = pd.DataFrame([
            {"word": w, "lemma": info.get("lemma"), "level": info.get("level"), "notes": info.get("explain_cn")}
            for w, info in st.session_state.vocab.items()
        ])
        st.dataframe(df)
        # simple review quiz: present random words and ask for translation
        if st.button("å¤ä¹ æ¨¡å¼ (ç®€å•)"):
            st.session_state.review_queue = list(st.session_state.vocab.keys())
            st.experimental_rerun()
        if "review_queue" in st.session_state and st.session_state.review_queue:
            word = st.session_state.review_queue.pop(0)
            st.write("è¯·ç¿»è¯‘æˆ–è§£é‡Š: ", word)
            ans = st.text_input("ä½ çš„ç­”æ¡ˆ", key=f"ans_{word}")
            if st.button("æäº¤", key=f"submit_{word}"):
                st.success("å·²è®°å½•ï¼ˆæ­¤å¤„ä¸ºæ¼”ç¤ºï¼Œæœªè¯„åˆ†ï¼‰")
                st.experimental_rerun()

# -------------------------
# Page: TOPIK Proficiency Test
# -------------------------
TEST_QUESTIONS = [
    {
        "q": "ë‹¤ìŒ ì¤‘ 'ë°œìŒ'ì˜ ëœ»ìœ¼ë¡œ ê°€ì¥ ì ì ˆí•œ ê²ƒì€?",
        "options": ["A. æ­Œæ›²", "B. å‘éŸ³", "C. ç»ƒä¹ ", "D. æ”¶å°¾"],
        "answer": "B"
    },
    {
        "q": "ë‹¤ìŒ ë¬¸ì¥ì˜ ë¹ˆì¹¸ì— ë“¤ì–´ê°ˆ í‘œí˜„ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ê²ƒì€? 'ë‚˜ëŠ” ë§¤ì¼ ( ) ì—°ìŠµí•œë‹¤.'",
        "options": ["A. ê°€ì‚¬", "B. ë¦¬í—ˆì„¤", "C. ë°œìŒ", "D. ì‹ ê³¡"],
        "answer": "C"
    },
    {
        "q": "ë‹¤ìŒ ë¬¸ì¥ í•´ì„ìœ¼ë¡œ ì˜³ì€ ê²ƒì€? 'ì´ ë…¸ë˜ëŠ” ê°€ì‚¬ì— ì–´ë ¤ìš´ í‘œí˜„ì´ ë§ì•„ìš”.'",
        "options": ["A. è¿™é¦–æ­Œæ²¡æœ‰æ­Œè¯ã€‚", "B. æ­Œè¯æœ‰å¾ˆå¤šç®€å•è¡¨è¾¾ã€‚", "C. æ­Œè¯æœ‰å¾ˆå¤šéš¾æ‡‚çš„è¡¨è¾¾ã€‚", "D. æ­Œè¯å¾ˆçŸ­ã€‚"],
        "answer": "C"
    },
    {
        "q": "ë‹¤ìŒ ì¤‘ 'ë°›ì¹¨'ì— ëŒ€í•œ ì„¤ëª…ìœ¼ë¡œ ë§ëŠ” ê²ƒì€?",
        "options": ["A. ë‹¨ì–´ì˜ ì²«ì†Œë¦¬", "B. ìŒì ˆ ëì˜ ììŒ", "C. ë¬¸ì¥ì˜ ë", "D. ë™ì‚¬ì˜ ì–´ê·¼"],
        "answer": "B"
    },
    {
        "q": "ë‹¤ìŒ ë¹ˆì¹¸ì— ë“¤ì–´ê°ˆ ê°€ì¥ ì–´ìš¸ë¦¬ëŠ” í‘œí˜„: 'ì, ìš°ë¦¬ ë‹¤ì‹œ í•œ ë²ˆ ( ).'",
        "options": ["A. ê°€ì‚¬", "B. í•´ë³¼ê¹Œìš”", "C. ë°›ì¹¨", "D. ë¦¬í—ˆì„¤"],
        "answer": "B"
    }
]

def page_test():
    st.header(T("test"))
    if st.session_state.test_results:
        res = st.session_state.test_results
        st.success(f"{T('score')}: {res['score']} / {len(TEST_QUESTIONS)}")
        st.info(f"{T('level')}: {res['level']}")
        if st.button("é‡æ–°æµ‹è¯•"):
            st.session_state.test_results = None
            st.experimental_rerun()
        return

    answers = []
    st.write("å…±è®¡é¢˜ç›®ï¼š", len(TEST_QUESTIONS))
    form = st.form("test_form")
    user_ans = []
    for i, q in enumerate(TEST_QUESTIONS):
        form.markdown(f"**{i+1}. {q['q']}**")
        key = f"q_{i}"
        choice = form.radio("", q["options"], key=key)
        user_ans.append(choice[0])  # first char A/B/C...
    submitted = form.form_submit_button("æäº¤ç­”æ¡ˆ")
    if submitted:
        score = sum(1 for i, q in enumerate(TEST_QUESTIONS) if user_ans[i] == q["answer"])
        # Simple mapping to TOPIK estimate (demo heuristic)
        if score >= 4:
            level = "TOPIK 3-4 (ä¸­ä¸Š)"
        elif score >= 2:
            level = "TOPIK 2 (ä¸­çº§åˆæœŸ)"
        else:
            level = "TOPIK 1 (åˆå­¦)"
        st.session_state.test_results = {"score": score, "level": level}
        st.experimental_rerun()

# -------------------------
# Page: Idol Insight (ç¤ºä¾‹åˆ†æ)
# -------------------------
# Simulated corpus & analysis
IDOL_CORPUS = [
    "ì•ˆë…•í•˜ì„¸ìš” ì—¬ëŸ¬ë¶„ ì˜¤ëŠ˜ì€ ì‹ ê³¡ ë¦¬í—ˆì„¤ì´ ìˆì–´ìš”",
    "ì´ ë…¸ë˜ëŠ” ê°€ì‚¬ì— ì–´ë ¤ìš´ í‘œí˜„ì´ ë§ì•„ìš”",
    "ì—°ìŠµí•˜ë©´ ê¸ˆë°© ìµí ìˆ˜ ìˆìŠµë‹ˆë‹¤",
    "ë°œìŒì— ì‹ ê²½ ì¨ì£¼ì„¸ìš” íŠ¹íˆ ë°›ì¹¨ ë°œìŒ",
    "ìš°ë¦¬ ë‹¤ì‹œ í•œ ë²ˆ í•´ë³¼ê¹Œìš”"
]

def page_insight():
    st.header(T("insight"))
    st.write("ç¤ºä¾‹ï¼šBTS æˆå‘˜ è¯­è¨€ç”»åƒï¼ˆæ¼”ç¤ºæ•°æ®ï¼‰")
    # simple frequency
    from collections import Counter
    words = []
    for s in IDOL_CORPUS:
        for tok in s.split():
            words.append(tok.strip())
    freq = Counter(words)
    top = freq.most_common(10)
    df_top = pd.DataFrame(top, columns=["word", "count"])
    st.subheader("é«˜é¢‘è¯ Top10")
    st.table(df_top)
    # bar chart
    fig, ax = plt.subplots()
    ax.bar(df_top['word'], df_top['count'])
    ax.set_xlabel("è¯")
    ax.set_ylabel("å‡ºç°æ¬¡æ•°")
    st.pyplot(fig)

    # adverb-like tokens simulation (we treat some tokens as adverbs)
    advs = {"íŠ¹íˆ": 5, "ê¸ˆë°©": 3, "ë‹¤ì‹œ": 4}
    st.subheader("å¸¸ç”¨å‰¯è¯ç»Ÿè®¡ (ç¤ºä¾‹)")
    adv_df = pd.DataFrame(list(advs.items()), columns=["adverb", "count"])
    st.table(adv_df)
    fig2, ax2 = plt.subplots()
    ax2.pie(adv_df['count'], labels=adv_df['adverb'], autopct='%1.1f%%')
    st.pyplot(fig2)

    # voice / mood analysis (simulated)
    mood = {"Informal": 12, "Formal": 3, "Casual": 8}
    st.subheader("è¯­æ€åˆ†æ (ç¤ºä¾‹)")
    mood_df = pd.DataFrame(list(mood.items()), columns=["mood", "count"])
    st.bar_chart(mood_df.set_index("mood"))

    st.markdown("---")
    st.write("æç¤ºï¼šæ­¤å¤„ä¸ºç¤ºä¾‹åˆ†æã€‚å®é™…å¯æ›¿æ¢ä¸ºçœŸå®ç›´æ’­è¯­æ–™å¹¶ä½¿ç”¨ NLP æ¨¡å‹æå–å…³é”®è¯ã€æƒ…æ„Ÿä¸è¯­æ€ã€‚")

# -------------------------
# Router
# -------------------------
if "page" not in locals():
    page = page  # from sidebar selection

if page == "Live Study":
    page_live_study()
elif page == T("test"):
    page_test()
elif page == T("insight"):
    page_insight()
elif page == T("vocab_book"):
    page_vocab()
else:
    st.write("Unknown page")

# -------------------------
# Footer: small utilities (export subtitles, show session state)
# -------------------------
st.sidebar.markdown("---")
st.sidebar.write("Demo project â€” ianå­—å¹• MVP")
if st.sidebar.button("å¯¼å‡ºå½“å‰å­—å¹•ä¸º SRT"):
    srt = subs_to_srt(st.session_state.subs_buffer)
    st.sidebar.download_button("Download SRT", srt, file_name="ian_subtitles.srt", mime="text/plain")
if st.sidebar.button("å¯¼å‡ºå½“å‰å­—å¹•ä¸º TXT"):
    txt = subs_to_txt(st.session_state.subs_buffer)
    st.sidebar.download_button("Download TXT", txt, file_name="ian_subtitles.txt", mime="text/plain")

# End of app
